{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import thread_the_needle as ttn\n",
    "\n",
    "\n",
    "from vi_ppo.actor_critic import ActorCritic\n",
    "from vi_ppo.nets.mlp import Mlp\n",
    "from vi_ppo.nets.cnn import Cnn\n",
    "from vi_ppo.modules import ThreadTheNeedleModule\n",
    "from vi_ppo.vae import Vae\n",
    "import lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space:  (1, 64, 64)\n",
      "Action space:  4\n"
     ]
    }
   ],
   "source": [
    "# Initialise the environment\n",
    "env = ttn.make(\"thread_the_needle\")\n",
    "\n",
    "# make the actor critic model\n",
    "d = env.observation_space.shape\n",
    "n_a = env.action_space.n\n",
    "hidden_dims = 16\n",
    "\n",
    "\n",
    "print(\"Observation space: \", d) \n",
    "print(\"Action space: \", n_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13be4b7c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.state_values[:-1].reshape(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 2,  2,  2, ...,  0,  0,  0],\n",
       "         [ 2,  2,  2, ...,  0,  0,  0],\n",
       "         [ 2,  2,  3, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [24, 26, 28, ...,  3,  3,  3],\n",
       "         [22, 24, 25, ...,  3,  3,  2],\n",
       "         [21, 22, 23, ...,  3,  3,  2]]], shape=(1, 64, 64)),\n",
       " -0.1,\n",
       " False,\n",
       " False,\n",
       " {'start_state': 285,\n",
       "  'successor_state': 265,\n",
       "  'state_values': 0.5159661069298376})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddind dimensions: 169\n"
     ]
    }
   ],
   "source": [
    "# Use a CNN to extract features from the image\n",
    "feature_extractor_config = Cnn.config_cls(\n",
    "    input_channels=1, \n",
    "    channels=[8,16,1], \n",
    "    kernel_sizes=[8,4,1], \n",
    "    strides=[2,2,1], \n",
    "    padding=[0,0,0],\n",
    "    flatten_output=True,\n",
    "    activation=\"silu\",\n",
    "    )\n",
    "feature_extractor = Cnn(feature_extractor_config)\n",
    "embedding_dims = feature_extractor.calculate_output_shape(input_shape=(1,64,64))[1]\n",
    "print(f\"Number of embeddind dimensions: {embedding_dims}\")\n",
    "\n",
    "# Construct the state inference model\n",
    "z_dim = 2\n",
    "encoder_config = Mlp.config_cls(\n",
    "    input_dims=embedding_dims, \n",
    "    output_dims=z_dim * 2, \n",
    "    hidden_dims=embedding_dims, \n",
    "    n_layers=1, \n",
    "    )\n",
    "decoder_config = Mlp.config_cls(\n",
    "    input_dims=z_dim, \n",
    "    output_dims=embedding_dims, \n",
    "    hidden_dims=embedding_dims, \n",
    "    n_layers=1, \n",
    "    )\n",
    "\n",
    "vae_config  = Vae.config_cls(\n",
    "    z_dim=z_dim, \n",
    "    sigma=1e-4, \n",
    "    beta=1.,\n",
    "    )\n",
    "vae = Vae(\n",
    "    vae_config,\n",
    "    encoder=Mlp(encoder_config), \n",
    "    decoder=Mlp(decoder_config)\n",
    "    )\n",
    "\n",
    "action_embeddings = nn.Embedding(n_a, z_dim)\n",
    "\n",
    "transition_network = Mlp(\n",
    "    Mlp.config_cls(\n",
    "        input_dims=embedding_dims * 2, \n",
    "        output_dims=embedding_dims, \n",
    "        hidden_dims=embedding_dims, \n",
    "        n_layers=1\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "actor_config = Mlp.config_cls(\n",
    "    input_dims=embedding_dims, \n",
    "    output_dims=n_a, \n",
    "    hidden_dims=hidden_dims,\n",
    "    n_layers=1, \n",
    ")\n",
    "critic_config = Mlp.config_cls(\n",
    "    input_dims=embedding_dims, \n",
    "    output_dims=1, \n",
    "    hidden_dims=hidden_dims, \n",
    "    n_layers=1, \n",
    ")\n",
    "ac_config = ActorCritic.config_cls(\n",
    "    clip_epsilon=0.2, \n",
    "    value_coeff=0.5, \n",
    "    entropy_coeff=0.01\n",
    ")\n",
    "\n",
    "model = ActorCritic(\n",
    "    ac_config, \n",
    "    actor_net=Mlp(actor_config), \n",
    "    critic=Mlp(critic_config), \n",
    "    feature_extractor=feature_extractor,\n",
    "    state_vae = vae,\n",
    "    action_embeddings=action_embeddings,\n",
    "    transition_network=transition_network,\n",
    "    )\n",
    "\n",
    "\n",
    "# module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nicholasfranklin/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name         | Type        | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | actor_critic | ActorCritic | 153 K  | train\n",
      "-----------------------------------------------------\n",
      "153 K     Trainable params\n",
      "0         Non-trainable params\n",
      "153 K     Total params\n",
      "0.613     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/nicholasfranklin/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/nicholasfranklin/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30184e4c0fb4556996f42fcfc5967a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholasfranklin/Projects/vi_ppo/src/vi_ppo/modules.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(obs, dtype=torch.float32).to(self.device)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Mlp' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m logger \u001b[38;5;241m=\u001b[39m TensorBoardLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../lightning_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_the_needle/notebook\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, logger\u001b[38;5;241m=\u001b[39mlogger)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1026\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1026\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:322\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    320\u001b[0m             batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_optimization\u001b[38;5;241m.\u001b[39mrun(trainer\u001b[38;5;241m.\u001b[39moptimizers[\u001b[38;5;241m0\u001b[39m], batch_idx, kwargs)\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m             batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/manual.py:94\u001b[0m, in \u001b[0;36m_ManualOptimization.run\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_run_start()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mStopIteration\u001b[39;00m):  \u001b[38;5;66;03m# no loop to break at this level\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_run_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/manual.py:114\u001b[0m, in \u001b[0;36m_ManualOptimization.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwargs  \u001b[38;5;66;03m# release the batch from memory\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:323\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 323\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    326\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/vi_ppo/src/vi_ppo/modules.py:162\u001b[0m, in \u001b[0;36mGymnasiumModule.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    159\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m loss, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_critic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Manual optimization steps\u001b[39;00m\n\u001b[1;32m    165\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/vi_ppo/src/vi_ppo/actor_critic.py:145\u001b[0m, in \u001b[0;36mActorCritic.loss\u001b[0;34m(self, batch, return_metrics)\u001b[0m\n\u001b[1;32m    142\u001b[0m entropy \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mentropy()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# VAE loss\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m vae_loss, vae_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvae_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Total loss\u001b[39;00m\n\u001b[1;32m    148\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    149\u001b[0m     policy_loss\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvalue_coeff \u001b[38;5;241m*\u001b[39m value_loss\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mentropy_coeff \u001b[38;5;241m*\u001b[39m entropy\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvae_loss_coeff \u001b[38;5;241m*\u001b[39m vae_loss\n\u001b[1;32m    153\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/vi_ppo/src/vi_ppo/actor_critic.py:84\u001b[0m, in \u001b[0;36mActorCritic.vae_loss\u001b[0;34m(self, features, batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# get the next state\u001b[39;00m\n\u001b[1;32m     83\u001b[0m next_obs_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_observations\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 84\u001b[0m _vae_loss, next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransition_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m(\n\u001b[1;32m     85\u001b[0m     features, next_obs_features\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m vae_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _vae_loss\n\u001b[1;32m     89\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_embeddings(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_ppo/lib/python3.10/site-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Mlp' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "\n",
    "config = ThreadTheNeedleModule.config_class(lr=3e-4)\n",
    "module = ThreadTheNeedleModule(actor_critic=model, env=env, config=config)\n",
    "\n",
    "logger = TensorBoardLogger(\"../lightning_logs\", name=\"thread_the_needle/notebook\")\n",
    "trainer = pl.Trainer(max_epochs=20, logger=logger)\n",
    "\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_ppo.utils.plotting import visualize_rollout\n",
    "visualize_rollout(env, module.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(module.buffer.terminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(module.buffer.truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(module.buffer.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.end_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_ppo.utils.vae import estimate_graph_laplacian\n",
    "laplacian = estimate_graph_laplacian(module.actor_critic, module.buffer, normalized=False)\n",
    "plt.imshow(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian.sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# convert the laplacian into a graph\n",
    "laplacian = estimate_graph_laplacian(module.actor_critic, module.buffer, normalized=True)\n",
    "\n",
    "edges = np.argwhere(laplacian.numpy())\n",
    "edges = [(i, j) for i, j in edges if i != j]  # remove self-edges\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "nx.draw_networkx(G, with_labels=False, node_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vi_ppo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
