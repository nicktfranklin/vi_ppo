{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Box2D is not installed, you can install it by run `pip install swig` followed by `pip install \"gymnasium[box2d]\"`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/vi_ppo/.venv/lib/python3.10/site-packages/gymnasium/envs/box2d/bipedal_walker.py:15\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBox2D\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m         circleShape,\n\u001b[1;32m     18\u001b[0m         contactListener,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         revoluteJointDef,\n\u001b[1;32m     23\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Box2D'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialise the environment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLunarLander-v3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Reset the environment to generate the first observation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m observation, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/vi_ppo/.venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:702\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m env_spec\u001b[38;5;241m.\u001b[39mentry_point\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# Assume it's a string\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m \u001b[43mload_env_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# Determine if to use the rendering\u001b[39;00m\n\u001b[1;32m    705\u001b[0m render_modes: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/vi_ppo/.venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:549\u001b[0m, in \u001b[0;36mload_env_creator\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an environment with name of style ``\"(import path):(environment name)\"`` and returns the environment creation function, normally the environment class type.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m    The environment constructor for the given environment name.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    548\u001b[0m mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 549\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:992\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Projects/vi_ppo/.venv/lib/python3.10/site-packages/gymnasium/envs/box2d/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbipedal_walker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BipedalWalker, BipedalWalkerHardcore\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcar_racing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CarRacing\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlunar_lander\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LunarLander, LunarLanderContinuous\n",
      "File \u001b[0;32m~/Projects/vi_ppo/.venv/lib/python3.10/site-packages/gymnasium/envs/box2d/bipedal_walker.py:25\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m         circleShape,\n\u001b[1;32m     18\u001b[0m         contactListener,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         revoluteJointDef,\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyNotInstalled(\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox2D is not installed, you can install it by run `pip install swig` followed by `pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgymnasium[box2d]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     27\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpygame\u001b[39;00m\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: Box2D is not installed, you can install it by run `pip install swig` followed by `pip install \"gymnasium[box2d]\"`"
     ]
    }
   ],
   "source": [
    "# Initialise the environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "# Reset the environment to generate the first observation\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(1000):\n",
    "    # this is where you would insert your policy\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # step (transition) through the environment with the action\n",
    "    # receiving the next observation, reward and if the episode has terminated or truncated\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # If the episode has ended then we can reset to start a new episode\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple dataset object (OARO tuple with GAE values).\n",
    "# OARO stands for Observation, Action, Reward, Observation (successor observation)\n",
    "OARODataset = namedtuple('OARODataset', \n",
    "                         ['observations', 'actions', 'rewards', 'next_observations', \n",
    "                          'advantages', 'returns', 'log_probs'])\n",
    "\n",
    "\n",
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.observations = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.next_observations = []  # Successor observations\n",
    "        self.terminated = []\n",
    "        self.truncated = []\n",
    "        self.infos = []\n",
    "        self.log_probs = []\n",
    "\n",
    "    def add(self, obs, act, rew, next_obs, terminated, truncated, info, log_probs = None):\n",
    "        \"\"\"\n",
    "        Add a transition to the buffer.\n",
    "\n",
    "        Args:\n",
    "            obs: The current observation.\n",
    "            act: The action taken.\n",
    "            rew: The reward received.\n",
    "            next_obs: The successor observation.\n",
    "            terminated: Boolean flag indicating if the episode terminated.\n",
    "            truncated: Boolean flag indicating if the episode was truncated.\n",
    "            info: Additional info from the environment.\n",
    "        \"\"\"\n",
    "        self.observations.append(obs)\n",
    "        self.actions.append(act)\n",
    "        self.rewards.append(rew)\n",
    "        self.next_observations.append(next_obs)\n",
    "        self.terminated.append(terminated)\n",
    "        self.truncated.append(truncated)\n",
    "        self.infos.append(info)\n",
    "        self.log_probs.append(log_probs)\n",
    "\n",
    "    def clear(self):\n",
    "        self.observations.clear()\n",
    "        self.actions.clear()\n",
    "        self.rewards.clear()\n",
    "        self.next_observations.clear()\n",
    "        self.terminated.clear()\n",
    "        self.truncated.clear()\n",
    "        self.infos.clear()\n",
    "        self.log_probs.clear()\n",
    "\n",
    "    def compute_gae(self, values, gamma: float = 0.99, gae_lambda: float = 1.0):\n",
    "        \"\"\"\n",
    "        Compute Generalized Advantage Estimation (GAE) for the collected experiences.\n",
    "\n",
    "        Args:\n",
    "            values (list or np.array): Value estimates for each state in the buffer.\n",
    "                                       It should have length len(self.rewards) + 1 (the extra element is\n",
    "                                       the value estimate for the last next_observation).\n",
    "            gamma (float): Discount factor.\n",
    "            gae_lambda (float): GAE lambda parameter.\n",
    "\n",
    "        Returns:\n",
    "            advantages (list): Advantage estimates for each timestep.\n",
    "            returns (list): Computed returns (advantages + value estimates) for each timestep.\n",
    "        \"\"\"\n",
    "        assert len(values) == len(self.rewards) + 1, \"Expected len(values) == len(rewards) + 1\"\n",
    "        advantages = [0] * len(self.rewards)\n",
    "        gae = 0\n",
    "        # Iterate in reverse order over the collected experiences\n",
    "        for t in reversed(range(len(self.rewards))):\n",
    "            # If the episode ended at this timestep, treat it as terminal\n",
    "            done = self.terminated[t] or self.truncated[t]\n",
    "            next_value = 0 if done else values[t + 1]\n",
    "            delta = self.rewards[t] + gamma * next_value - values[t]\n",
    "            # When done, the future advantage is zero\n",
    "            gae = delta + gamma * gae_lambda * (0 if done else gae)\n",
    "            advantages[t] = gae\n",
    "        # Compute returns (target values) as advantages plus the baseline values\n",
    "        returns = [adv + val for adv, val in zip(advantages, values[:-1])]\n",
    "        return advantages, returns     \n",
    "    \n",
    "    def compute_rewards_to_go(self, gamma):\n",
    "        \"\"\"\n",
    "        Compute the Monte Carlo estimate of rewards-to-go for the collected experiences.\n",
    "\n",
    "        Args:\n",
    "            gamma (float): Discount factor.\n",
    "\n",
    "        Returns:\n",
    "            returns (list): Monte Carlo estimates of rewards-to-go for each timestep.\n",
    "        \"\"\"\n",
    "        returns = [0] * len(self.rewards)\n",
    "        R = 0\n",
    "        # Process the rewards in reverse order\n",
    "        for t in reversed(range(len(self.rewards))):\n",
    "            # Reset the cumulative reward if the episode ended at this step.\n",
    "            if self.terminated[t] or self.truncated[t]:\n",
    "                R = self.rewards[t]\n",
    "            else:\n",
    "                R = self.rewards[t] + gamma * R\n",
    "            returns[t] = R\n",
    "        return returns\n",
    "    \n",
    "    def get_dataset(self, values: list | np.ndarray | None = None, gamma: float = 0.99, gae_lambda: float = 1.0):\n",
    "        \"\"\"\n",
    "        Compute the dataset containing the OARO tuple along with advantage and return estimates.\n",
    "\n",
    "        If value estimates are provided, GAE is computed; otherwise, a Monte Carlo estimate of rewards-to-go is used\n",
    "        for both returns and advantages.\n",
    "\n",
    "        Args:\n",
    "            gamma (float): Discount factor.\n",
    "            lam (float): GAE lambda parameter.\n",
    "            values (list or np.array, optional): Value estimates for each observation \n",
    "                                                 (must have length len(rewards)+1). Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            OARODataset: A namedtuple with fields:\n",
    "                - observations: list of observations.\n",
    "                - actions: list of actions.\n",
    "                - rewards: list of rewards.\n",
    "                - next_observations: list of successor observations.\n",
    "                - advantages: computed advantage estimates.\n",
    "                - returns: computed return values.\n",
    "        \"\"\"\n",
    "\n",
    "        if values is None:\n",
    "            values = self.compute_rewards_to_go(gamma)\n",
    "        advantages, returns = self.compute_gae(values, gamma, gae_lambda)\n",
    "        \n",
    "        dataset = OARODataset(\n",
    "            observations=np.stack(self.observations),\n",
    "            actions=np.stack(self.actions),\n",
    "            rewards=np.stack(self.rewards),\n",
    "            next_observations=np.stack(self.next_observations),\n",
    "            advantages=np.stack(advantages),\n",
    "            returns=np.stack(returns),\n",
    "            log_probs=self.log_probs if any(self.log_probs) else None\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "state_inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
